### ğŸŒ‰ Enterprise Batch Data Pipeline: Big Data Processing with Spark

Batch Data Ingestion & Processing with Spark  
**Enterprise Edition** (WSL + VS Code + Data Lake + Partitioning)  

**Programming Language:** Python  
**Work Environment:** Linux Server Environment  
**Code Editor:** VS Code (Remote WSL)  
**Command Line Interface:** Bash  
**Distributed Data Processing Engine:** PySpark  

---

##  ğŸ‘¨â€ğŸ« Dosen Pembimbing
[![GitHub - Muhayat Lab](https://img.shields.io/badge/GitHub-Muhayat--Lab-181717?logo=github&style=for-the-badge)](https://github.com/muhayat-lab)

##  ğŸ‘¨â€ğŸ’» Developer
[![GitHub - Zharvian](https://img.shields.io/badge/GitHub-Zharvians-007ACC?logo=github&style=for-the-badge)](https://github.com/Zharvians)

**Nama:** Muhammad Ade Ramadhani  
**NPM:** 230104040213  
**Kelas:** TI23A  

---

## ğŸ—‚ Project Overview

Enterprise batch data pipeline yang dirancang untuk:

- Mengambil data mentah (raw) dari sumber CSV  
- Membersihkan data (cleaning) dan menghapus duplikasi/NA  
- Transformasi data (hitung total_amount per transaksi)  
- Agregasi data (top products, revenue per kategori, rata-rata transaksi per customer)  
- Menyimpan data ke **Data Lake** dalam format Parquet, termasuk **partitioned by category**  

Pipeline ini dibuat untuk **pembelajaran Big Data Enterprise** dengan **PySpark di WSL**.

---

## ğŸ“ Struktur Project
```bash 
bigdata-project/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # CSV input
â”‚ â”œâ”€â”€ clean/ # Data bersih
â”‚ â””â”€â”€ curated/ # Hasil agregasi & analytics
â”œâ”€â”€ logs/ # Log pipeline
â”œâ”€â”€ scripts/ # Script pipeline PySpark
â”œâ”€â”€ venv/ # Virtual environment Python
â””â”€â”€ README.md
```

---

## âš™ Setup & Requirements

1. **WSL Ubuntu 22.04**  
2. **Python 3.12+** + `python3-venv`  
3. **Java OpenJDK 17** (JAVA_HOME diset)  
4. **PySpark 3.5+** (install via `pip install pyspark==3.5.2`)  
5. **VS Code Remote WSL** untuk editing dan running script  

---

## ğŸš€ Cara Menjalankan Pipeline

1. Aktifkan virtual environment:

```bash
source venv/bin/activate
```

2. Jalankan pipeline:
```bash
python scripts/batch_pipeline_enterprise.py
```

3. Output akan disimpan di:
```bash
data/clean/parquet/ â†’ Clean layer
data/curated/category_revenue/ â†’ Revenue per kategori
data/curated/top_products/ â†’ Top products
data/curated/avg_transaction/ â†’ Rata-rata transaksi per customer
data/clean/partitioned_by_category/ â†’ Partitioned clean layer
```

---

## ğŸ“Œ Catatan
```bash
- Pastikan folder data/raw/ sudah berisi file ecommerce_raw.csv sebelum menjalankan pipeline
- .gitignore menyertakan: venv/, logs/, data/clean/, data/curated/ agar tidak ikut di-push ke GitHub
```

---

### ğŸ“œ License
```bash
Proyek ini dibuat untuk keperluan akademik
Praktikum 2 â€“ Teknologi Big Data

Dilarang menggunakan untuk kepentingan komersial.
Â© 2026 â€” 230104040213. Seluruh hak dilindungi.
```
